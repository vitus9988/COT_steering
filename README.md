# CoT Steering without Prompting

This repository aims to develop **Chain-of-Thought (CoT) Steering** based on the *CoT without Prompting* paradigm.  
We focus on improving the modelâ€™s latent reasoning ability **without additional training**, by leveraging **Test-Time Scaling** techniques.

## ğŸ” Overview

Traditional CoT methods rely on explicit prompts or handcrafted examples to elicit step-by-step reasoning.  
This project explores how CoT dynamics can be *steered internally* during inference without such external guidance, offering a scalable and prompt-free approach to reasoning.

Key objectives:
- Steer latent CoT behavior without prompt engineering
- Apply test-time modulation techniques to enhance reasoning
- Evaluate controllability and performance across reasoning tasks

## ğŸ“ Repository Structure

```
.
â”œâ”€â”€ configs/          # Experiment configurations
â”œâ”€â”€ src/              # Core implementation
â”œâ”€â”€ eval/             # Evaluation scripts and benchmarks
â”œâ”€â”€ scripts/          # Training / inference scripts
â””â”€â”€ README.md         # Project documentation
```

## âš™ï¸ Installation

```bash
git clone https://github.com/your-username/cot-steering.git
cd cot-steering
pip install -r requirements.txt
```

> ğŸ“ Requires Python 3.8+ and PyTorch.

## ğŸš€ Usage

Run inference with CoT Steering enabled:

```bash
python src/inference.py --config configs/example.yaml
```

## ğŸ“Š Evaluation

We evaluated the effectiveness of **CoT Steering without Prompting** on the **2025 Korean CSAT (ìˆ˜ëŠ¥) Language Section**, using the model `FuseAI/FuseO1-DeepSeekR1-QwQ-SkyT1-32B-Preview`.

Through CoT Steering, we achieved a significant improvement in performance without any additional training.

### ğŸ“ˆ Performance Comparison

| Model                                      | Score (Language Section) |
|-------------------------------------------|---------------------------|
| HyperClovaX     | 61                        |
| gpt 4o       | 75                        |
| deepseek r1     | 78                        |
| O1 mini      | 78                        |
| FuseO1-DeepSeekR1-QwQ-SkyT1-32B(Base line)            | 67                    |
| FuseO1-DeepSeekR1-QwQ-SkyT1-32B(COT Steering)            | **84**                    |
| O1 preview             | 97                    |

The baseline model achieved a score in the 60s range. After applying our CoT Steering mechanism, the model reached a score of **84**, demonstrating the potential of test-time reasoning modulation in high-stakes language comprehension tasks.

We enhanced the modelâ€™s latent reasoning capability through **CoT Steering**, enabling notable performance gains without additional training.

Notably, while most comparison baselines utilize models ranging from **100B to 685B parameters**, our approach achieved competitive performance using a **33B-parameter** model. This result highlights the effectiveness and efficiency of CoT Steering, demonstrating its potential to unlock strong reasoning abilities even in relatively smaller models.

While steering can be applied either at the **token level** or in the **latent space** or using a **potential function**, we observed no significant performance difference between the two approaches.
Given this, we adopted the **token-level steering method**, which offers greater `flexibility` and `computational efficiency`, making it more **practical for real-world deployment**.




## ğŸ“Œ Citation

Coming soon.

## ğŸ§‘â€ğŸ’» Contributors

- Seugyoo Lee (@DopeorNope-Lee)


## ğŸ“„ License

This project is licensed under the MIT License.
