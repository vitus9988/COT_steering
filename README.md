# CoT Steering without Prompting

This repository aims to develop **Chain-of-Thought (CoT) Steering** based on the *CoT without Prompting* paradigm.  
We focus on improving the modelâ€™s latent reasoning ability **without additional training**, by leveraging **Test-Time Scaling** techniques.

## ğŸ” Overview

Traditional CoT methods rely on explicit prompts or handcrafted examples to elicit step-by-step reasoning.  
This project explores how CoT dynamics can be *steered internally* during inference without such external guidance, offering a scalable and prompt-free approach to reasoning.

Key objectives:
- Steer latent CoT behavior without prompt engineering
- Apply test-time modulation techniques to enhance reasoning
- Evaluate controllability and performance across reasoning tasks

## ğŸ“ Repository Structure

```
.
â”œâ”€â”€ configs/          # Experiment configurations
â”œâ”€â”€ src/              # Core implementation
â”œâ”€â”€ eval/             # Evaluation scripts and benchmarks
â”œâ”€â”€ scripts/          # Training / inference scripts
â””â”€â”€ README.md         # Project documentation
```

## âš™ï¸ Installation

```bash
git clone https://github.com/your-username/cot-steering.git
cd cot-steering
pip install -r requirements.txt
```

> ğŸ“ Requires Python 3.8+ and PyTorch.

## ğŸš€ Usage

Run inference with CoT Steering enabled:

```bash
python src/inference.py --config configs/example.yaml
```

## ğŸ“Š Evaluation

We evaluated the effectiveness of **CoT Steering without Prompting** on the **2025 Korean CSAT (ìˆ˜ëŠ¥) Language Section**, using the model `FuseAI/FuseO1-DeepSeekR1-QwQ-SkyT1-32B-Preview`.

Through CoT Steering, we achieved a significant improvement in performance without any additional training.

### ğŸ“ˆ Performance Comparison

| Model                                      | Score (Language Section) |
|-------------------------------------------|---------------------------|
| HyperClovaX     | 61                        |
| gpt 4o       | 75                        |
| deepseek r1     | 78                        |
| O1 mini      | 78                        |
| FuseO1-DeepSeekR1-QwQ-SkyT1-32B(Base line)            | 67                    |
| FuseO1-DeepSeekR1-QwQ-SkyT1-32B            | **84**                    |
| O1 preview             | 97                    |

The baseline model achieved a score in the 60s range. After applying our CoT Steering mechanism, the model reached a score of **84**, demonstrating the potential of test-time reasoning modulation in high-stakes language comprehension tasks.

Further evaluations on different subjects and reasoning benchmarks are in progress.

## ğŸ“Œ Citation

Coming soon.

## ğŸ§‘â€ğŸ’» Contributors

- Your Name (@your_handle)
- Additional contributors welcome!

## ğŸ“„ License

This project is licensed under the MIT License.
